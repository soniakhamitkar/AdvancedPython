{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4327e864-700e-43b6-81d6-5918672b2913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f610b2d-e0cb-441c-8e79-8666043fb232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /opt/anaconda3/lib/python3.12/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: mediapipe in /opt/anaconda3/lib/python3.12/site-packages (0.10.21)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.12/site-packages (3.8.4)\n",
      "Requirement already satisfied: yt-dlp in /opt/anaconda3/lib/python3.12/site-packages (2025.3.31)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /opt/anaconda3/lib/python3.12/site-packages (from opencv-python) (1.26.4)\n",
      "Requirement already satisfied: absl-py in /opt/anaconda3/lib/python3.12/site-packages (from mediapipe) (2.2.2)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from mediapipe) (25.1.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from mediapipe) (25.2.10)\n",
      "Requirement already satisfied: jax in /opt/anaconda3/lib/python3.12/site-packages (from mediapipe) (0.6.0)\n",
      "Requirement already satisfied: jaxlib in /opt/anaconda3/lib/python3.12/site-packages (from mediapipe) (0.6.0)\n",
      "Requirement already satisfied: opencv-contrib-python in /opt/anaconda3/lib/python3.12/site-packages (from mediapipe) (4.11.0.86)\n",
      "Requirement already satisfied: protobuf<5,>=4.25.3 in /opt/anaconda3/lib/python3.12/site-packages (from mediapipe) (4.25.6)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in /opt/anaconda3/lib/python3.12/site-packages (from mediapipe) (0.5.1)\n",
      "Requirement already satisfied: sentencepiece in /opt/anaconda3/lib/python3.12/site-packages (from mediapipe) (0.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: CFFI>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sounddevice>=0.4.4->mediapipe) (1.16.0)\n",
      "Requirement already satisfied: ml_dtypes>=0.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from jax->mediapipe) (0.5.1)\n",
      "Requirement already satisfied: opt_einsum in /opt/anaconda3/lib/python3.12/site-packages (from jax->mediapipe) (3.4.0)\n",
      "Requirement already satisfied: scipy>=1.11.1 in /opt/anaconda3/lib/python3.12/site-packages (from jax->mediapipe) (1.13.1)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/lib/python3.12/site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1 — Install Dependencies\n",
    "# Run this in your terminal or Jupyter cell (with ! or % as needed)\n",
    "%pip install opencv-python mediapipe matplotlib yt-dlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2165a024-83ff-4692-b2df-4a2ca9201b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1745364443.437116 16831707 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M2\n"
     ]
    }
   ],
   "source": [
    "# Cell 2 — Imports & Utilities (with local trim)\n",
    "import cv2\n",
    "import numpy as np\n",
    "import re\n",
    "import mediapipe as mp\n",
    "from yt_dlp import YoutubeDL\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# MediaPipe pose setup\n",
    "mp_pose = mp.solutions.pose\n",
    "pose    = mp_pose.Pose(\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "def download_youtube_mp4(youtube_url, output_path, filename=\"dive_raw.mp4\"):\n",
    "    \"\"\"Download a YouTube URL (including shorts) via yt-dlp.\"\"\"\n",
    "    ydl_opts = {\n",
    "        'format': 'mp4',\n",
    "        'outtmpl': f'{output_path}/{filename}',\n",
    "        'quiet': True,\n",
    "    }\n",
    "    with YoutubeDL(ydl_opts) as ydl:\n",
    "        ydl.download([youtube_url])\n",
    "    return f\"{output_path}/{filename}\"\n",
    "\n",
    "def trim_clip_local(input_path, start_s, end_s, output_path):\n",
    "    \"\"\"\n",
    "    Trim a portion [start_s, end_s] from input_path and save to output_path\n",
    "    using OpenCV only (no ffmpeg).\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    w   = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    h   = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (w, h))\n",
    "\n",
    "    start_frame = int(start_s * fps)\n",
    "    end_frame   = int(end_s * fps)\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "    for _ in range(start_frame, end_frame):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        out.write(frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    return output_path\n",
    "\n",
    "def extract_frames(video_path):\n",
    "    \"\"\"Load all frames from a video into a list.\"\"\"\n",
    "    cap, frames = cv2.VideoCapture(video_path), []\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frames.append(frame)\n",
    "    cap.release()\n",
    "    return frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f04b18d3-143e-4c30-9cf7-adc35f157cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from: https://www.youtube.com/watch?v=cWi67iT1Mes\n",
      "Downloaded to: ./dive_raw1.mp4\n"
     ]
    }
   ],
   "source": [
    "# Cell 3 — Download Your Shorts Clip\n",
    "raw_url = \"https://youtube.com/shorts/cWi67iT1Mes?si=TDfU78iKeNOsKn6D\"\n",
    "\n",
    "# 1) Extract the video ID from a /shorts/ or watch URL\n",
    "m = re.search(r\"(?:shorts/|watch\\?v=)([\\w-]+)\", raw_url)\n",
    "if not m:\n",
    "    raise ValueError(f\"Could not parse video ID from {raw_url}\")\n",
    "video_id = m.group(1)\n",
    "\n",
    "# 2) Normalize to a watch URL and download\n",
    "watch_url = f\"https://www.youtube.com/watch?v={video_id}\"\n",
    "print(\"Downloading from:\", watch_url)\n",
    "raw_path = download_youtube_mp4(watch_url, output_path=\".\", filename=\"dive_raw1.mp4\")\n",
    "print(\"Downloaded to:\", raw_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17267e38-540c-4ae7-84d1-a03dd439b8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4 — Auto‑Detect & Trim the Three Dives\n",
    "frames_all = extract_frames(raw_path)\n",
    "\n",
    "# Compute frame‐difference magnitudes\n",
    "diffs = [\n",
    "    np.sum(cv2.absdiff(\n",
    "        cv2.cvtColor(frames_all[i-1], cv2.COLOR_BGR2GRAY),\n",
    "        cv2.cvtColor(frames_all[i],   cv2.COLOR_BGR2GRAY)\n",
    "    ))\n",
    "    for i in range(1, len(frames_all))\n",
    "]\n",
    "\n",
    "# Pick the top‑3 splash peaks\n",
    "peaks = np.argpartition(diffs, -3)[-3:]\n",
    "peaks = sorted(peaks)\n",
    "\n",
    "# Convert to seconds\n",
    "cap = cv2.VideoCapture(raw_path)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "cap.release()\n",
    "entry_times = [p/fps for p in peaks]\n",
    "print(\"Detected splash times (s):\", entry_times)\n",
    "\n",
    "# Trim a small window around each splash\n",
    "clip_paths = []\n",
    "for idx, t in enumerate(entry_times, start=1):\n",
    "    start, end = max(0, t-1), t+2  # 1 s before entry, 2 s after\n",
    "    out_name = f\"dive{idx}.mp4\"\n",
    "    trim_clip_local(raw_path, start, end, out_name)\n",
    "    clip_paths.append(out_name)\n",
    "    print(f\" → Created {out_name}\")\n",
    "\n",
    "# `clip_paths` now holds [\"dive1.mp4\",\"dive2.mp4\",\"dive3.mp4\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08019f3-2d7a-4d62-b1e1-13be5165e32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5 — Core Analysis Functions (updated for LEFT_/RIGHT_ landmarks)\n",
    "import math\n",
    "\n",
    "def get_landmarks(frames):\n",
    "    lm_list = []\n",
    "    for f in frames:\n",
    "        rgb = cv2.cvtColor(f, cv2.COLOR_BGR2RGB)\n",
    "        res = pose.process(rgb).pose_landmarks\n",
    "        if not res:\n",
    "            lm_list.append(None)\n",
    "            continue\n",
    "        pts = {\n",
    "            mp_pose.PoseLandmark(i).name: (lm.x, lm.y)\n",
    "            for i, lm in enumerate(res.landmark)\n",
    "        }\n",
    "        lm_list.append(pts)\n",
    "    return lm_list\n",
    "\n",
    "def detect_takeoff_and_entry(frames, landmarks):\n",
    "    # 1) Hip vertical velocity (average of left+right hips)\n",
    "    y_vals = []\n",
    "    for lm in landmarks:\n",
    "        if lm and 'LEFT_HIP' in lm and 'RIGHT_HIP' in lm:\n",
    "            y_vals.append((lm['LEFT_HIP'][1] + lm['RIGHT_HIP'][1]) / 2)\n",
    "        else:\n",
    "            y_vals.append(None)\n",
    "    vels = []\n",
    "    for i in range(1, len(y_vals)):\n",
    "        if y_vals[i] is not None and y_vals[i-1] is not None:\n",
    "            vels.append(y_vals[i-1] - y_vals[i])  # upward = positive\n",
    "        else:\n",
    "            vels.append(0)\n",
    "    takeoff_idx = int(np.argmax(vels))\n",
    "\n",
    "    # 2) Splash via frame-difference\n",
    "    diffs = []\n",
    "    for i in range(1, len(frames)):\n",
    "        g1 = cv2.cvtColor(frames[i-1], cv2.COLOR_BGR2GRAY)\n",
    "        g2 = cv2.cvtColor(frames[i],   cv2.COLOR_BGR2GRAY)\n",
    "        diffs.append(np.sum(cv2.absdiff(g2, g1)))\n",
    "    entry_idx = int(np.argmax(diffs))\n",
    "\n",
    "    return takeoff_idx, entry_idx\n",
    "\n",
    "def compute_metrics(frames, landmarks, to_idx, en_idx):\n",
    "    lm_e = landmarks[en_idx]\n",
    "    # Average shoulders and hips\n",
    "    shoulder = (np.array(lm_e['LEFT_SHOULDER']) +\n",
    "                np.array(lm_e['RIGHT_SHOULDER'])) / 2\n",
    "    hip      = (np.array(lm_e['LEFT_HIP']) +\n",
    "                np.array(lm_e['RIGHT_HIP'])) / 2\n",
    "\n",
    "    # Entry angle: torso vector vs vertical\n",
    "    vec = hip - shoulder\n",
    "    vertical = np.array([0, 1])\n",
    "    entry_angle = math.degrees(\n",
    "        math.acos(np.dot(vec/np.linalg.norm(vec), vertical))\n",
    "    )\n",
    "\n",
    "    # Straightness: average deviation of ankle from shoulder‑hip line\n",
    "    devs = []\n",
    "    for lm in landmarks[to_idx:en_idx]:\n",
    "        if not lm: \n",
    "            continue\n",
    "        ankle = (np.array(lm['LEFT_ANKLE']) +\n",
    "                 np.array(lm['RIGHT_ANKLE'])) / 2\n",
    "        dev = np.linalg.norm(\n",
    "            np.cross(hip-shoulder, shoulder-ankle)\n",
    "        ) / np.linalg.norm(hip-shoulder)\n",
    "        devs.append(dev)\n",
    "    straightness = max(0, 1 - np.mean(devs)*10)\n",
    "\n",
    "    # Splash area: diff mask at entry\n",
    "    g1 = cv2.cvtColor(frames[en_idx-1], cv2.COLOR_BGR2GRAY)\n",
    "    g2 = cv2.cvtColor(frames[en_idx],   cv2.COLOR_BGR2GRAY)\n",
    "    diff = cv2.absdiff(g2, g1)\n",
    "    _, thresh = cv2.threshold(diff, 30, 255, cv2.THRESH_BINARY)\n",
    "    splash_area = np.sum(thresh > 0)\n",
    "\n",
    "    return {\n",
    "        'entry_angle': entry_angle,\n",
    "        'straightness': straightness,\n",
    "        'splash_area': splash_area\n",
    "    }\n",
    "\n",
    "def score_dive(metrics, weights=(0.4, 0.3, 0.3)):\n",
    "    a = max(0, 1 - metrics['entry_angle']/30)\n",
    "    b = metrics['straightness']\n",
    "    c = max(0, 1 - metrics['splash_area']/50000)\n",
    "    w1, w2, w3 = weights\n",
    "    return 10 * (w1*a + w2*b + w3*c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636ab363-f41e-40d5-bcc4-203d6ce2a614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6 — Analyze All Three Clips (with landmark‐existence checks)\n",
    "\n",
    "def find_valid_frame(landmarks, idx):\n",
    "    \"\"\"\n",
    "    Return the nearest index to `idx` where landmarks[idx] is not None.\n",
    "    Search outward until you find one or exhaust the list.\n",
    "    \"\"\"\n",
    "    n = len(landmarks)\n",
    "    if landmarks[idx] is not None:\n",
    "        return idx\n",
    "    for d in range(1, n):\n",
    "        for sign in (+1, -1):\n",
    "            i = idx + sign*d\n",
    "            if 0 <= i < n and landmarks[i] is not None:\n",
    "                return i\n",
    "    return None  # no valid frame found\n",
    "\n",
    "results = {}\n",
    "\n",
    "for path in clip_paths:\n",
    "    fr = extract_frames(path)\n",
    "    lm = get_landmarks(fr)\n",
    "    to, en = detect_takeoff_and_entry(fr, lm)\n",
    "\n",
    "    # Find valid landmark frames\n",
    "    valid_to = find_valid_frame(lm, to)\n",
    "    valid_en = find_valid_frame(lm, en)\n",
    "    if valid_to is None or valid_en is None:\n",
    "        print(f\"Warning: no valid landmarks for {path}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Compute metrics using the valid indices\n",
    "    m = compute_metrics(fr, lm, valid_to, valid_en)\n",
    "    s = score_dive(m)\n",
    "    results[path] = {\n",
    "        'takeoff_frame': valid_to,\n",
    "        'entry_frame':   valid_en,\n",
    "        'metrics':       m,\n",
    "        'score':         round(s, 2)\n",
    "    }\n",
    "\n",
    "import pprint\n",
    "pprint.pprint(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887aa030-67de-4546-9435-6cf8bd7dc6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7 — Presentable Table of Dive Results\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# Flatten your `results` dict\n",
    "rows = []\n",
    "for clip, data in results.items():\n",
    "    rows.append({\n",
    "        'Clip': clip,\n",
    "        'Takeoff Frame': data['takeoff_frame'],\n",
    "        'Entry Frame': data['entry_frame'],\n",
    "        'Entry Angle (°)': round(data['metrics']['entry_angle'], 2),\n",
    "        'Straightness': round(data['metrics']['straightness'], 3),\n",
    "        'Splash Area': data['metrics']['splash_area'],\n",
    "        'Score': data['score']\n",
    "    })\n",
    "\n",
    "# Create and show the DataFrame\n",
    "df = pd.DataFrame(rows)\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2750ab5c-4616-4fb4-8121-c8cf3ada2601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8 — Visualize One Dive’s Velocity & Splash (corrected)\n",
    "\n",
    "# 1) Load frames & landmarks for the first clip\n",
    "fr = extract_frames(clip_paths[0])\n",
    "lm = get_landmarks(fr)\n",
    "\n",
    "# 2) Compute vertical hip velocity (avg of left+right hips)\n",
    "vels = []\n",
    "for i in range(1, len(lm)):\n",
    "    prev, cur = lm[i-1], lm[i]\n",
    "    if prev and cur and all(k in prev for k in ('LEFT_HIP','RIGHT_HIP')) \\\n",
    "               and all(k in cur  for k in ('LEFT_HIP','RIGHT_HIP')):\n",
    "        y_prev = (prev['LEFT_HIP'][1] + prev['RIGHT_HIP'][1]) / 2\n",
    "        y_cur  = (cur ['LEFT_HIP'][1] + cur ['RIGHT_HIP'][1]) / 2\n",
    "        vels.append(y_prev - y_cur)\n",
    "    else:\n",
    "        vels.append(0)\n",
    "\n",
    "# 3) Plot velocity\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8,3))\n",
    "plt.plot(vels)\n",
    "plt.title(\"Hip Vertical Velocity\")\n",
    "plt.xlabel(\"Frame\")\n",
    "plt.ylabel(\"Δy\")\n",
    "plt.show()\n",
    "\n",
    "# 4) Show splash mask at entry\n",
    "entry_idx = results[clip_paths[0]]['entry_frame']\n",
    "g1 = cv2.cvtColor(fr[entry_idx-1], cv2.COLOR_BGR2GRAY)\n",
    "g2 = cv2.cvtColor(fr[entry_idx],   cv2.COLOR_BGR2GRAY)\n",
    "diff = cv2.absdiff(g2, g1)\n",
    "_, mask = cv2.threshold(diff, 30, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.imshow(mask, cmap='gray')\n",
    "plt.title(f\"Splash Mask (Frame {entry_idx})\")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a833bf36-a16c-4e08-8d91-c8e9dbd8ea9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9 — Presentable Recommendations (Markdown format)\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "def present_recommendations(results):\n",
    "    for clip, data in results.items():\n",
    "        angle     = data['metrics']['entry_angle']\n",
    "        straight  = data['metrics']['straightness']\n",
    "        splash    = data['metrics']['splash_area']\n",
    "        score     = data['score']\n",
    "        \n",
    "        recs = []\n",
    "        # Entry Angle\n",
    "        if angle > 30:\n",
    "            recs.append(f\"**Entry Angle**: {angle:.1f}° is off‑vertical; aim for under 10° for a pencil entry.\")\n",
    "        else:\n",
    "            recs.append(f\"**Entry Angle**: {angle:.1f}° – excellent alignment; keep it up!\")\n",
    "        # Body Straightness\n",
    "        if straight < 0.5:\n",
    "            recs.append(f\"**Body Straightness**: {straight:.2f} – focus on a tighter streamline: shoulders, hips, and ankles in one line.\")\n",
    "        else:\n",
    "            recs.append(f\"**Body Straightness**: {straight:.2f} – great mid‑air alignment!\")\n",
    "        # Splash Size\n",
    "        if splash > 50000:\n",
    "            recs.append(f\"**Splash Size**: {splash} px – work on reducing splash by keeping the body tight at entry.\")\n",
    "        else:\n",
    "            recs.append(f\"**Splash Size**: {splash} px – good entry with minimal splash!\")\n",
    "        \n",
    "        md = (\n",
    "            f\"---\\n\"\n",
    "            f\"### {clip}  ‒  Score: **{score:.2f}**\\n\\n\" +\n",
    "            \"\\n\".join(f\"- {r}\" for r in recs) +\n",
    "            \"\\n\"\n",
    "        )\n",
    "        display(Markdown(md))\n",
    "\n",
    "# Call it\n",
    "present_recommendations(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc93a6b-9d6b-409d-a4e8-abdcf5769c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10 — Export Annotated Videos with Overlays\n",
    "\n",
    "import os\n",
    "from cv2 import putText, rectangle, FONT_HERSHEY_SIMPLEX\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "def export_annotated(video_path, out_path, landmarks, takeoff_idx, entry_idx, score):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    w   = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    h   = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(out_path, fourcc, fps, (w, h))\n",
    "    \n",
    "    frame_idx = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # draw skeleton if we have landmarks\n",
    "        lm = landmarks[frame_idx]\n",
    "        if lm:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                frame, \n",
    "                pose.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)).pose_landmarks,\n",
    "                mp_pose.POSE_CONNECTIONS\n",
    "            )\n",
    "        \n",
    "        # highlight takeoff\n",
    "        if frame_idx == takeoff_idx:\n",
    "            rectangle(frame, (10,10), (160,50), (0,255,0), 2)\n",
    "            putText(frame, \"TAKEOFF\", (15,40), FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
    "        # highlight entry\n",
    "        if frame_idx == entry_idx:\n",
    "            rectangle(frame, (10,60), (160,100), (0,0,255), 2)\n",
    "            putText(frame, \"ENTRY\", (15,95), FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "            \n",
    "        # stamp score\n",
    "        putText(frame, f\"Score: {score:.1f}\", (w-200,h-20),\n",
    "                FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "        \n",
    "        out.write(frame)\n",
    "        frame_idx += 1\n",
    "    \n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(f\"Annotated video written to {out_path}\")\n",
    "\n",
    "# Run it for each clip\n",
    "for clip, data in results.items():\n",
    "    ann_path = f\"annotated_{clip}\"\n",
    "    fr = extract_frames(clip)\n",
    "    lm = get_landmarks(fr)\n",
    "    export_annotated(\n",
    "        clip,\n",
    "        ann_path,\n",
    "        lm,\n",
    "        data['takeoff_frame'],\n",
    "        data['entry_frame'],\n",
    "        data['score']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c531c5-37ab-4182-b7c2-1755269386b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
